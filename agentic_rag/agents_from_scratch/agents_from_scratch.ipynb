{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charan/VSCode/GITHUB/Assets_Youtube_Videos/agentic_rag/venv/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:743: UserWarning: Parameters [decoding_method, max_new_tokens, stop_sequences] is/are not recognized and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the average weight of a Border Collie and a Scottish Terrier, then add them together to get the combined weight.\n",
      "Action: average_dog_weight: Border Collie\n",
      "PAUSE\n",
      "\n",
      "Thought: Now I need to find the average weight of a Scottish Terrier.\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      "\n",
      "Thought: Now that I have the average weights of both breeds, I can add them together to get the combined weight.\n",
      "Action: calculate: 22 + 10\n",
      "PAUSE\n",
      " -- running average_dog_weight Border Collie\n",
      "Observation: a Border Collies average weight is 37 lbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charan/VSCode/GITHUB/Assets_Youtube_Videos/agentic_rag/venv/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:743: UserWarning: Parameters [decoding_method, max_new_tokens, stop_sequences] is/are not recognized and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: Now that I know the average weight of a Border Collie, I can find the average weight of a Scottish Terrier.\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      " -- running average_dog_weight Scottish Terrier\n",
      "Observation: Scottish Terriers average 20 lbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charan/VSCode/GITHUB/Assets_Youtube_Videos/agentic_rag/venv/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:743: UserWarning: Parameters [decoding_method, max_new_tokens, stop_sequences] is/are not recognized and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: Now that I have the average weights of both breeds, I can add them together to get the combined weight.\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      " -- running calculate 37 + 20\n",
      "Observation: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charan/VSCode/GITHUB/Assets_Youtube_Videos/agentic_rag/venv/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/inference/base_model_inference.py:743: UserWarning: Parameters [decoding_method, max_new_tokens, stop_sequences] is/are not recognized and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Watsonx chat function\n",
    "def watsonx_llm(messages):\n",
    "    \"\"\"\n",
    "    Generate a chat completion using IBM Watsonx models.\n",
    "\n",
    "    Parameters:\n",
    "    - messages (list of dict): The messages for the chat session.\n",
    "    - model_size (int, optional): Specifies the model size. Default is 8.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated response content.\n",
    "    \"\"\"\n",
    "    model_id = f\"meta-llama/llama-3-1-8b-instruct\"\n",
    "\n",
    "    # Fetch environment variables\n",
    "    api_key = os.getenv(\"WX_KEY\")\n",
    "    url = os.getenv(\"WX_URL\")\n",
    "    project_id = os.getenv(\"WX_PID\")\n",
    "\n",
    "    if not all([api_key, project_id, model_id]):\n",
    "        raise Exception(\n",
    "            \"Missing required environment variables: WX_KEY, WX_URL, or WX_PID.\"\n",
    "        )\n",
    "\n",
    "    # Adjusted parameters\n",
    "    params = {\n",
    "        GenParams.DECODING_METHOD: \"sample\",\n",
    "        GenParams.MAX_NEW_TOKENS: 256,\n",
    "        GenParams.TEMPERATURE: 0.0,\n",
    "        GenParams.STOP_SEQUENCES: [\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "    }\n",
    "\n",
    "    # Setup credentials\n",
    "    credentials = Credentials(api_key=api_key, url=url)\n",
    "\n",
    "    # Instantiate ModelInference\n",
    "    model_inference = ModelInference(\n",
    "        model_id=model_id, params=params, credentials=credentials, project_id=project_id\n",
    "    )\n",
    "\n",
    "    # Call the chat method\n",
    "    response = model_inference.chat(messages=messages)\n",
    "\n",
    "    # Extract and return the generated content\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Define the ReAct Agent class\n",
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        return watsonx_llm(self.messages)\n",
    "\n",
    "\n",
    "# Define available actions\n",
    "def calculate(what):\n",
    "    try:\n",
    "        return eval(what)\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {e}\"\n",
    "\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\":\n",
    "        return \"Scottish Terriers average 20 lbs\"\n",
    "    elif name in \"Border Collie\":\n",
    "        return \"a Border Collies average weight is 37 lbs\"\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return \"a toy poodles average weight is 7 lbs\"\n",
    "    else:\n",
    "        return \"An average dog weighs 50 lbs\"\n",
    "\n",
    "\n",
    "def calculator(expression):\n",
    "    \"\"\"\n",
    "    A more advanced calculator that supports complex mathematical expressions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safeguard to limit the operations\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "# Add tools to known actions\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight,\n",
    "    \"calculator\": calculator,\n",
    "}\n",
    "\n",
    "# Initialize the prompt\n",
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer.\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary.\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "Returns the average weight of a dog when given the breed.\n",
    "\n",
    "calculator:\n",
    "e.g. calculator: (5 + 10) * (2 ** 3)\n",
    "Runs a more advanced calculation and returns the result. It can handle complex mathematical expressions.\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the result of (3 + 7) * 2?\n",
    "Thought: I should use the calculator tool to compute the result.\n",
    "Action: calculator: (3 + 7) * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: The result is 20\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: The result of (3 + 7) * 2 is 20.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Define the query function with ReAct loop\n",
    "action_re = re.compile(r\"^Action: (\\w+): (.*)$\")\n",
    "\n",
    "\n",
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [action_re.match(a) for a in result.split(\"\\n\") if action_re.match(a)]\n",
    "        if actions:\n",
    "            action, action_input = actions[0].groups()\n",
    "            if action not in known_actions:\n",
    "                raise Exception(f\"Unknown action: {action}: {action_input}\")\n",
    "            print(f\" -- running {action} {action_input}\")\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = f\"Observation: {observation}\"\n",
    "        else:\n",
    "            return\n",
    "\n",
    "\n",
    "# Example usage\n",
    "question = \"I have 2 dogs, a Border Collie and a Scottish Terrier. What is their combined weight?\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import required modules\n",
    "# import os  # For interacting with operating system environment variables\n",
    "# import re  # For working with regular expressions\n",
    "# from dotenv import load_dotenv  # To load environment variables from a .env file\n",
    "# from ibm_watsonx_ai import Credentials  # To manage API credentials for IBM Watsonx\n",
    "# from ibm_watsonx_ai.foundation_models import ModelInference  # To interface with Watsonx AI models\n",
    "# from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams  # Predefined parameter keys for text generation\n",
    "\n",
    "# # Load environment variables from a .env file\n",
    "# load_dotenv()\n",
    "\n",
    "# # Define a function to interact with Watsonx LLM (Large Language Model)\n",
    "# def watsonx_llm(messages):\n",
    "#     \"\"\"\n",
    "#     Generate a chat completion using IBM Watsonx models.\n",
    "\n",
    "#     Parameters:\n",
    "#     - messages (list of dict): A list of message objects that simulate a chat session.\n",
    "#       Each message contains a 'role' (e.g., user, system, assistant) and its 'content'.\n",
    "    \n",
    "#     Returns:\n",
    "#     - str: The response content generated by the model.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Specify the model ID to use, in this case, an IBM Watsonx LLaMA-based model\n",
    "#     model_id = f\"meta-llama/llama-3-1-8b-instruct\"\n",
    "\n",
    "#     # Fetch required environment variables for API authentication\n",
    "#     api_key = os.getenv(\"WX_KEY\")  # API key for Watsonx authentication\n",
    "#     url = os.getenv(\"WX_URL\")  # Base URL for the Watsonx service\n",
    "#     project_id = os.getenv(\"WX_PID\")  # Project ID associated with the Watsonx account\n",
    "\n",
    "#     # Ensure all required environment variables are available; raise an error otherwise\n",
    "#     if not all([api_key, project_id, model_id]):\n",
    "#         raise Exception(\n",
    "#             \"Missing required environment variables: WX_KEY, WX_URL, or WX_PID.\"\n",
    "#         )\n",
    "\n",
    "#     # Define parameters for text generation\n",
    "#     params = {\n",
    "#         GenParams.DECODING_METHOD: \"sample\",  # Specify the decoding method\n",
    "#         GenParams.MAX_NEW_TOKENS: 256,  # Set the maximum number of tokens to generate\n",
    "#         GenParams.TEMPERATURE: 0.0,  # Temperature for deterministic responses\n",
    "#         GenParams.STOP_SEQUENCES: [\"<|eot_id|>\", \"<|eom_id|>\"],  # Define stop sequences\n",
    "#     }\n",
    "\n",
    "#     # Initialize credentials object with API key and service URL\n",
    "#     credentials = Credentials(api_key=api_key, url=url)\n",
    "\n",
    "#     # Create a ModelInference instance to interact with the specified model\n",
    "#     model_inference = ModelInference(\n",
    "#         model_id=model_id, params=params, credentials=credentials, project_id=project_id\n",
    "#     )\n",
    "\n",
    "#     # Generate a response from the model using the provided messages\n",
    "#     response = model_inference.chat(messages=messages)\n",
    "\n",
    "#     # Return the content of the first choice in the response\n",
    "#     return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# # Define a class for a ReAct agent\n",
    "# class Agent:\n",
    "#     def __init__(self, system=\"\"):\n",
    "#         \"\"\"\n",
    "#         Initialize the agent with an optional system message.\n",
    "#         \"\"\"\n",
    "#         self.system = system  # System message for setting the agent's initial behavior\n",
    "#         self.messages = []  # List to store the chat history\n",
    "#         if self.system:  # If a system message is provided, add it to messages\n",
    "#             self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "#     def __call__(self, message):\n",
    "#         \"\"\"\n",
    "#         Add a user message and generate a response from the agent.\n",
    "#         \"\"\"\n",
    "#         self.messages.append({\"role\": \"user\", \"content\": message})  # Add user message\n",
    "#         result = self.execute()  # Generate a response\n",
    "#         self.messages.append({\"role\": \"assistant\", \"content\": result})  # Add assistant's response\n",
    "#         return result\n",
    "\n",
    "#     def execute(self):\n",
    "#         \"\"\"\n",
    "#         Execute the Watsonx model with the current messages.\n",
    "#         \"\"\"\n",
    "#         return watsonx_llm(self.messages)  # Use Watsonx LLM to generate a response\n",
    "\n",
    "# # Define actions for specific queries\n",
    "# def calculate(what):\n",
    "#     \"\"\"\n",
    "#     Perform a calculation based on the provided input string.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         return eval(what)  # Evaluate the input string as a Python expression\n",
    "#     except Exception as e:\n",
    "#         return f\"Error in calculation: {e}\"  # Handle errors gracefully\n",
    "\n",
    "# def average_dog_weight(name):\n",
    "#     \"\"\"\n",
    "#     Return the average weight of a dog based on its breed.\n",
    "#     \"\"\"\n",
    "#     if name in \"Scottish Terrier\":\n",
    "#         return \"Scottish Terriers average 20 lbs\"\n",
    "#     elif name in \"Border Collie\":\n",
    "#         return \"a Border Collies average weight is 37 lbs\"\n",
    "#     elif name in \"Toy Poodle\":\n",
    "#         return \"a toy poodles average weight is 7 lbs\"\n",
    "#     else:\n",
    "#         return \"An average dog weighs 50 lbs\"\n",
    "\n",
    "# def calculator(expression):\n",
    "#     \"\"\"\n",
    "#     Evaluate complex mathematical expressions securely.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Evaluate the expression with restricted built-ins for security\n",
    "#         result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "#         return result\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {e}\"  # Handle errors\n",
    "\n",
    "# # Create a dictionary of known actions for ReAct\n",
    "# known_actions = {\n",
    "#     \"calculate\": calculate,  # Simple calculator action\n",
    "#     \"average_dog_weight\": average_dog_weight,  # Retrieve average dog weight\n",
    "#     \"calculator\": calculator,  # Advanced calculator action\n",
    "# }\n",
    "\n",
    "# # Prompt to instruct the agent on its behavior\n",
    "# prompt = \"\"\"\n",
    "# You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "# At the end of the loop you output an Answer.\n",
    "# Use Thought to describe your thoughts about the question you have been asked.\n",
    "# Use Action to run one of the actions available to you - then return PAUSE.\n",
    "# Observation will be the result of running those actions.\n",
    "\n",
    "# Your available actions are:\n",
    "\n",
    "# calculate:\n",
    "# e.g. calculate: 4 * 7 / 3\n",
    "# Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary.\n",
    "\n",
    "# average_dog_weight:\n",
    "# e.g. average_dog_weight: Collie\n",
    "# Returns the average weight of a dog when given the breed.\n",
    "\n",
    "# calculator:\n",
    "# e.g. calculator: (5 + 10) * (2 ** 3)\n",
    "# Runs a more advanced calculation and returns the result. It can handle complex mathematical expressions.\n",
    "\n",
    "# Example session:\n",
    "\n",
    "# Question: What is the result of (3 + 7) * 2?\n",
    "# Thought: I should use the calculator tool to compute the result.\n",
    "# Action: calculator: (3 + 7) * 2\n",
    "# PAUSE\n",
    "\n",
    "# You will be called again with this:\n",
    "\n",
    "# Observation: The result is 20\n",
    "\n",
    "# You then output:\n",
    "\n",
    "# Answer: The result of (3 + 7) * 2 is 20.\n",
    "# \"\"\".strip()\n",
    "\n",
    "# # Define a query function with a ReAct loop\n",
    "# action_re = re.compile(r\"^Action: (\\w+): (.*)$\")  # Regex to parse actions\n",
    "\n",
    "# def query(question, max_turns=5):\n",
    "#     \"\"\"\n",
    "#     Process a question in a loop using the ReAct framework.\n",
    "#     \"\"\"\n",
    "#     i = 0  # Initialize loop counter\n",
    "#     bot = Agent(prompt)  # Create an agent with the defined prompt\n",
    "#     next_prompt = question  # Set the initial prompt to the question\n",
    "#     while i < max_turns:  # Limit the number of turns to prevent infinite loops\n",
    "#         i += 1\n",
    "#         result = bot(next_prompt)  # Generate a response from the agent\n",
    "#         print(result)  # Print the result\n",
    "#         actions = [action_re.match(a) for a in result.split(\"\\n\") if action_re.match(a)]  # Parse actions\n",
    "#         if actions:  # If an action is found\n",
    "#             action, action_input = actions[0].groups()  # Extract action name and input\n",
    "#             if action not in known_actions:  # Check if action is recognized\n",
    "#                 raise Exception(f\"Unknown action: {action}: {action_input}\")  # Handle unknown actions\n",
    "#             print(f\" -- running {action} {action_input}\")  # Log the action\n",
    "#             observation = known_actions[action](action_input)  # Execute the action\n",
    "#             print(\"Observation:\", observation)  # Print the observation\n",
    "#             next_prompt = f\"Observation: {observation}\"  # Update the prompt with the observation\n",
    "#         else:  # If no actions remain, terminate\n",
    "#             return\n",
    "\n",
    "# # Example usage of the query function\n",
    "# question = \"I have 2 dogs, a Border Collie and a Scottish Terrier. What is their combined weight?\"\n",
    "# query(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
