{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2f2621-074e-45a3-b892-9fd4ac5dbc2a",
   "metadata": {
    "id": "5c2f2621-074e-45a3-b892-9fd4ac5dbc2a",
    "language": "python"
   },
   "source": [
    "# Agentic RAG Using CrewAI & LangChain\n",
    "\n",
    "We are going to see how agents can be involved in the RAG system to rtrieve the most relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408f415-d51c-4d75-ad71-e809b7072778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:52:51.355586Z",
     "iopub.status.busy": "2024-08-06T08:52:51.355253Z",
     "iopub.status.idle": "2024-08-06T08:53:07.107101Z",
     "shell.execute_reply": "2024-08-06T08:53:07.105613Z",
     "shell.execute_reply.started": "2024-08-06T08:52:51.355560Z"
    },
    "id": "2408f415-d51c-4d75-ad71-e809b7072778",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 sentence-transformers langchain-groq --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74a183-c473-4286-aa91-6ac1c89f8a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:53:11.142412Z",
     "iopub.status.busy": "2024-08-06T08:53:11.141324Z",
     "iopub.status.idle": "2024-08-06T08:53:17.696025Z",
     "shell.execute_reply": "2024-08-06T08:53:17.695307Z",
     "shell.execute_reply.started": "2024-08-06T08:53:11.142373Z"
    },
    "id": "7d74a183-c473-4286-aa91-6ac1c89f8a08",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from crewai_tools import PDFSearchTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from crewai_tools  import tool\n",
    "from crewai import Crew\n",
    "from crewai import Task\n",
    "from crewai import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537530b-c530-43d6-afb7-d6a24d237908",
   "metadata": {
    "id": "f537530b-c530-43d6-afb7-d6a24d237908",
    "language": "python"
   },
   "source": [
    "## Mention the Groq API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211674e-aed8-4732-beef-7c3922279138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:53:26.673091Z",
     "iopub.status.busy": "2024-08-06T08:53:26.672457Z",
     "iopub.status.idle": "2024-08-06T08:53:26.678191Z",
     "shell.execute_reply": "2024-08-06T08:53:26.677631Z",
     "shell.execute_reply.started": "2024-08-06T08:53:26.673058Z"
    },
    "id": "b211674e-aed8-4732-beef-7c3922279138",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set the API key\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61808e55-3a5c-4977-a36f-6487740d20c9",
   "metadata": {
    "id": "61808e55-3a5c-4977-a36f-6487740d20c9",
    "language": "python"
   },
   "source": [
    "## Mention the LLM being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3e7b8-04c1-4a4b-a78f-9f10cef13222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T08:54:42.224934Z",
     "iopub.status.busy": "2024-08-06T08:54:42.224560Z",
     "iopub.status.idle": "2024-08-06T08:54:42.268360Z",
     "shell.execute_reply": "2024-08-06T08:54:42.267668Z",
     "shell.execute_reply.started": "2024-08-06T08:54:42.224905Z"
    },
    "id": "dcb3e7b8-04c1-4a4b-a78f-9f10cef13222",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "    openai_api_key=os.environ['GROQ_API_KEY'],\n",
    "    model_name=\"groq/llama3-8b-8192\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfdc74-f167-4a14-a4d6-6094cb5b71a0",
   "metadata": {
    "id": "c2cfdc74-f167-4a14-a4d6-6094cb5b71a0",
    "language": "python"
   },
   "source": [
    "## Create a RAG tool variable to pass our PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d2f22-8667-4799-bf90-1a9fec1dc540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:10:08.404340Z",
     "iopub.status.busy": "2024-08-06T09:10:08.403918Z",
     "iopub.status.idle": "2024-08-06T09:10:12.883348Z",
     "shell.execute_reply": "2024-08-06T09:10:12.880732Z",
     "shell.execute_reply.started": "2024-08-06T09:10:08.404297Z"
    },
    "id": "d97d2f22-8667-4799-bf90-1a9fec1dc540",
    "language": "python",
    "outputId": "7af567bb-9421-42b8-b0e2-ccc53f44e04f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rag_tool = PDFSearchTool(pdf='test.pdf',\n",
    "    config=dict(\n",
    "        llm=dict(\n",
    "            provider=\"groq\", # or google, openai, anthropic, llama2, ...\n",
    "            config=dict(\n",
    "                model=\"llama3-8b-8192\",\n",
    "                # temperature=0.5,\n",
    "                # top_p=1,\n",
    "                # stream=true,\n",
    "            ),\n",
    "        ),\n",
    "        embedder=dict(\n",
    "            provider=\"huggingface\", # or openai, ollama, ...\n",
    "            config=dict(\n",
    "                model=\"BAAI/bge-small-en-v1.5\",\n",
    "                #task_type=\"retrieval_document\",\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e49ecd-7cd8-464c-be2f-5e4aa1f58de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:10:29.400488Z",
     "iopub.status.busy": "2024-08-06T09:10:29.399575Z",
     "iopub.status.idle": "2024-08-06T09:10:29.479174Z",
     "shell.execute_reply": "2024-08-06T09:10:29.475340Z",
     "shell.execute_reply.started": "2024-08-06T09:10:29.400441Z"
    },
    "id": "40e49ecd-7cd8-464c-be2f-5e4aa1f58de6",
    "language": "python",
    "outputId": "5b445b62-2530-4d09-98e4-94900be98cf3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rag_tool.run(\"How did self-attention mechanism evolve in large language models?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac98c3c-b02f-4680-8fab-99fbfa3c45a3",
   "metadata": {
    "id": "0ac98c3c-b02f-4680-8fab-99fbfa3c45a3",
    "language": "python"
   },
   "source": [
    "## Mention the Tavily API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b4e5e-a4c4-4b81-8d11-97b9f7eb1d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:10:33.516323Z",
     "iopub.status.busy": "2024-08-06T09:10:33.515939Z",
     "iopub.status.idle": "2024-08-06T09:10:33.520768Z",
     "shell.execute_reply": "2024-08-06T09:10:33.520117Z",
     "shell.execute_reply.started": "2024-08-06T09:10:33.516295Z"
    },
    "id": "4e1b4e5e-a4c4-4b81-8d11-97b9f7eb1d4f",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set the Tavily API key\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f3f46-0750-4d59-a56a-02d13b802223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:10:40.163940Z",
     "iopub.status.busy": "2024-08-06T09:10:40.163524Z",
     "iopub.status.idle": "2024-08-06T09:10:40.167780Z",
     "shell.execute_reply": "2024-08-06T09:10:40.167028Z",
     "shell.execute_reply.started": "2024-08-06T09:10:40.163904Z"
    },
    "id": "086f3f46-0750-4d59-a56a-02d13b802223",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445a6f5-ff84-4ee8-b633-f28be3d06b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:10:41.783474Z",
     "iopub.status.busy": "2024-08-06T09:10:41.782945Z",
     "iopub.status.idle": "2024-08-06T09:10:43.410666Z",
     "shell.execute_reply": "2024-08-06T09:10:43.409742Z",
     "shell.execute_reply.started": "2024-08-06T09:10:41.783445Z"
    },
    "id": "b445a6f5-ff84-4ee8-b633-f28be3d06b00",
    "language": "python",
    "outputId": "b7fd078d-d694-49c8-df5a-5c32495f96ad",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "web_search_tool.run(\"What is self-attention mechansim in large language models?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e69851-f7e3-4b9a-8c7c-7da0f7f04bde",
   "metadata": {
    "id": "d1e69851-f7e3-4b9a-8c7c-7da0f7f04bde",
    "language": "python"
   },
   "source": [
    "## Define a Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b371c-4b24-4c80-b833-971f56ad4c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:34.946830Z",
     "iopub.status.busy": "2024-08-06T09:11:34.946268Z",
     "iopub.status.idle": "2024-08-06T09:11:34.952558Z",
     "shell.execute_reply": "2024-08-06T09:11:34.951976Z",
     "shell.execute_reply.started": "2024-08-06T09:11:34.946789Z"
    },
    "id": "907b371c-4b24-4c80-b833-971f56ad4c1f",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def router_tool(question):\n",
    "  \"\"\"Router Function\"\"\"\n",
    "  if 'self-attention' in question:\n",
    "    return 'vectorstore'\n",
    "  else:\n",
    "    return 'web_search'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17dc59-0e72-4eaa-9654-400df6cb371e",
   "metadata": {
    "id": "be17dc59-0e72-4eaa-9654-400df6cb371e",
    "language": "python"
   },
   "source": [
    "## Create Agents to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cacf6a3-7f50-49d6-9ab0-b63433d7032c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:39.241558Z",
     "iopub.status.busy": "2024-08-06T09:11:39.241051Z",
     "iopub.status.idle": "2024-08-06T09:11:39.249728Z",
     "shell.execute_reply": "2024-08-06T09:11:39.248634Z",
     "shell.execute_reply.started": "2024-08-06T09:11:39.241517Z"
    },
    "id": "6cacf6a3-7f50-49d6-9ab0-b63433d7032c",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Router_Agent = Agent(\n",
    "  role='Router',\n",
    "  goal='Route user question to a vectorstore or web search',\n",
    "  backstory=(\n",
    "    \"You are an expert at routing a user question to a vectorstore or web search.\"\n",
    "    \"Use the vectorstore for questions on concept related to Retrieval-Augmented Generation.\"\n",
    "    \"You do not need to be stringent with the keywords in the question related to these topics. Otherwise, use web-search.\"\n",
    "  ),\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc04747-af23-4b19-9ece-6473c683f739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:41.155843Z",
     "iopub.status.busy": "2024-08-06T09:11:41.155481Z",
     "iopub.status.idle": "2024-08-06T09:11:41.162015Z",
     "shell.execute_reply": "2024-08-06T09:11:41.161341Z",
     "shell.execute_reply.started": "2024-08-06T09:11:41.155815Z"
    },
    "id": "4fc04747-af23-4b19-9ece-6473c683f739",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Retriever_Agent = Agent(\n",
    "role=\"Retriever\",\n",
    "goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
    "backstory=(\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the information present in the retrieved context to answer the question.\"\n",
    "    \"You have to provide a clear concise answer.\"\n",
    "),\n",
    "verbose=True,\n",
    "allow_delegation=False,\n",
    "llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ece7eb-37fa-450d-991b-16dd8abca495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:42.476081Z",
     "iopub.status.busy": "2024-08-06T09:11:42.475654Z",
     "iopub.status.idle": "2024-08-06T09:11:42.489959Z",
     "shell.execute_reply": "2024-08-06T09:11:42.485582Z",
     "shell.execute_reply.started": "2024-08-06T09:11:42.476042Z"
    },
    "id": "25ece7eb-37fa-450d-991b-16dd8abca495",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Grader_agent =  Agent(\n",
    "  role='Answer Grader',\n",
    "  goal='Filter out erroneous retrievals',\n",
    "  backstory=(\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question.\"\n",
    "    \"If the document contains keywords related to the user question, grade it as relevant.\"\n",
    "    \"It does not need to be a stringent test.You have to make sure that the answer is relevant to the question.\"\n",
    "  ),\n",
    "  verbose=True,\n",
    "  allow_delegation=False,\n",
    "  llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb03f9-34bc-400b-8ada-80c08a71f1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:43.725087Z",
     "iopub.status.busy": "2024-08-06T09:11:43.724709Z",
     "iopub.status.idle": "2024-08-06T09:11:43.731283Z",
     "shell.execute_reply": "2024-08-06T09:11:43.730399Z",
     "shell.execute_reply.started": "2024-08-06T09:11:43.725058Z"
    },
    "id": "5cdb03f9-34bc-400b-8ada-80c08a71f1f8",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hallucination_grader = Agent(\n",
    "    role=\"Hallucination Grader\",\n",
    "    goal=\"Filter out hallucination\",\n",
    "    backstory=(\n",
    "        \"You are a hallucination grader assessing whether an answer is grounded in / supported by a set of facts.\"\n",
    "        \"Make sure you meticulously review the answer and check if the response provided is in alignmnet with the question asked\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3e019-18c4-4f33-be69-628274a544e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:48.359638Z",
     "iopub.status.busy": "2024-08-06T09:11:48.359179Z",
     "iopub.status.idle": "2024-08-06T09:11:48.372283Z",
     "shell.execute_reply": "2024-08-06T09:11:48.369019Z",
     "shell.execute_reply.started": "2024-08-06T09:11:48.359547Z"
    },
    "id": "b6e3e019-18c4-4f33-be69-628274a544e2",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "answer_grader = Agent(\n",
    "    role=\"Answer Grader\",\n",
    "    goal=\"Filter out hallucination from the answer.\",\n",
    "    backstory=(\n",
    "        \"You are a grader assessing whether an answer is useful to resolve a question.\"\n",
    "        \"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n",
    "        \"If the answer is relevant generate a clear and concise response.\"\n",
    "        \"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool'\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626670c9-717e-4bcd-b0b4-e4d9aaaae7eb",
   "metadata": {
    "id": "626670c9-717e-4bcd-b0b4-e4d9aaaae7eb",
    "language": "python"
   },
   "source": [
    "## Defining Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c9242-5b00-4e59-8e3d-d904c8e9d21f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:50.881204Z",
     "iopub.status.busy": "2024-08-06T09:11:50.880708Z",
     "iopub.status.idle": "2024-08-06T09:11:50.886480Z",
     "shell.execute_reply": "2024-08-06T09:11:50.885321Z",
     "shell.execute_reply.started": "2024-08-06T09:11:50.881168Z"
    },
    "id": "5e9c9242-5b00-4e59-8e3d-d904c8e9d21f",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "router_task = Task(\n",
    "    description=(\"Analyse the keywords in the question {question}\"\n",
    "    \"Based on the keywords decide whether it is eligible for a vectorstore search or a web search.\"\n",
    "    \"Return a single word 'vectorstore' if it is eligible for vectorstore search.\"\n",
    "    \"Return a single word 'websearch' if it is eligible for web search.\"\n",
    "    \"Do not provide any other premable or explaination.\"\n",
    "    ),\n",
    "    expected_output=(\"Give a binary choice 'websearch' or 'vectorstore' based on the question\"\n",
    "    \"Do not provide any other premable or explaination.\"),\n",
    "    agent=Router_Agent,\n",
    "    tools=[router_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a497afe-0fd0-4b9f-a97b-64d1b5518ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:52.682162Z",
     "iopub.status.busy": "2024-08-06T09:11:52.681767Z",
     "iopub.status.idle": "2024-08-06T09:11:52.689821Z",
     "shell.execute_reply": "2024-08-06T09:11:52.689037Z",
     "shell.execute_reply.started": "2024-08-06T09:11:52.682135Z"
    },
    "id": "5a497afe-0fd0-4b9f-a97b-64d1b5518ef0",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retriever_task = Task(\n",
    "    description=(\"Based on the response from the router task extract information for the question {question} with the help of the respective tool.\"\n",
    "    \"Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.\"\n",
    "    \"Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\"\n",
    "    ),\n",
    "    expected_output=(\"You should analyse the output of the 'router_task'\"\n",
    "    \"If the response is 'websearch' then use the web_search_tool to retrieve information from the web.\"\n",
    "    \"If the response is 'vectorstore' then use the rag_tool to retrieve information from the vectorstore.\"\n",
    "    \"Return a claer and consise text as response.\"),\n",
    "    agent=Retriever_Agent,\n",
    "    context=[router_task],\n",
    "   #tools=[retriever_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51750e-941d-41fa-b4d4-d36f7e56961e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:54.826584Z",
     "iopub.status.busy": "2024-08-06T09:11:54.825901Z",
     "iopub.status.idle": "2024-08-06T09:11:54.831307Z",
     "shell.execute_reply": "2024-08-06T09:11:54.830655Z",
     "shell.execute_reply.started": "2024-08-06T09:11:54.826545Z"
    },
    "id": "ce51750e-941d-41fa-b4d4-d36f7e56961e",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grader_task = Task(\n",
    "    description=(\"Based on the response from the retriever task for the quetion {question} evaluate whether the retrieved content is relevant to the question.\"\n",
    "    ),\n",
    "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the document is relevant to the question\"\n",
    "    \"You must answer 'yes' if the response from the 'retriever_task' is in alignment with the question asked.\"\n",
    "    \"You must answer 'no' if the response from the 'retriever_task' is not in alignment with the question asked.\"\n",
    "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
    "    agent=Grader_agent,\n",
    "    context=[retriever_task],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f89f1-caef-43ea-9ec7-614467f73a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:11:58.436290Z",
     "iopub.status.busy": "2024-08-06T09:11:58.435873Z",
     "iopub.status.idle": "2024-08-06T09:11:58.443357Z",
     "shell.execute_reply": "2024-08-06T09:11:58.442433Z",
     "shell.execute_reply.started": "2024-08-06T09:11:58.436248Z"
    },
    "id": "0d1f89f1-caef-43ea-9ec7-614467f73a3d",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hallucination_task = Task(\n",
    "    description=(\"Based on the response from the grader task for the quetion {question} evaluate whether the answer is grounded in / supported by a set of facts.\"),\n",
    "    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the answer is sync with the question asked\"\n",
    "    \"Respond 'yes' if the answer is in useful and contains fact about the question asked.\"\n",
    "    \"Respond 'no' if the answer is not useful and does not contains fact about the question asked.\"\n",
    "    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n",
    "    agent=hallucination_grader,\n",
    "    context=[grader_task],\n",
    ")\n",
    "\n",
    "answer_task = Task(\n",
    "    description=(\"Based on the response from the hallucination task for the quetion {question} evaluate whether the answer is useful to resolve the question.\"\n",
    "    \"If the answer is 'yes' return a clear and concise answer.\"\n",
    "    \"If the answer is 'no' then perform a 'websearch' and return the response\"),\n",
    "    expected_output=(\"Return a clear and concise response if the response from 'hallucination_task' is 'yes'.\"\n",
    "    \"Perform a web search using 'web_search_tool' and return ta clear and concise response only if the response from 'hallucination_task' is 'no'.\"\n",
    "    \"Otherwise respond as 'Sorry! unable to find a valid response'.\"),\n",
    "    context=[hallucination_task],\n",
    "    agent=answer_grader,\n",
    "    #tools=[answer_grader_tool],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190bfcbf-66bd-4ddc-bde6-2a96a002b8d7",
   "metadata": {
    "id": "190bfcbf-66bd-4ddc-bde6-2a96a002b8d7",
    "language": "python"
   },
   "source": [
    "## Define a flow for the use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9cbeb-d342-4da9-b442-b13e66ebbc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:12:01.597715Z",
     "iopub.status.busy": "2024-08-06T09:12:01.597364Z",
     "iopub.status.idle": "2024-08-06T09:12:01.609224Z",
     "shell.execute_reply": "2024-08-06T09:12:01.608693Z",
     "shell.execute_reply.started": "2024-08-06T09:12:01.597687Z"
    },
    "id": "75f9cbeb-d342-4da9-b442-b13e66ebbc96",
    "language": "python",
    "outputId": "3d1b3425-e4d2-4f7b-9dca-b046e7bbeafc",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rag_crew = Crew(\n",
    "    agents=[Router_Agent, Retriever_Agent, Grader_agent, hallucination_grader, answer_grader],\n",
    "    tasks=[router_task, retriever_task, grader_task, hallucination_task, answer_task],\n",
    "    verbose=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957af34a-ffc4-4283-9e26-3c936f8719cc",
   "metadata": {
    "id": "957af34a-ffc4-4283-9e26-3c936f8719cc",
    "language": "python"
   },
   "source": [
    "## Ask any query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e365a-cd84-4664-941e-5fb40765d7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:12:12.076469Z",
     "iopub.status.busy": "2024-08-06T09:12:12.075913Z",
     "iopub.status.idle": "2024-08-06T09:12:12.089371Z",
     "shell.execute_reply": "2024-08-06T09:12:12.082684Z",
     "shell.execute_reply.started": "2024-08-06T09:12:12.076435Z"
    },
    "id": "b98e365a-cd84-4664-941e-5fb40765d7dc",
    "language": "python",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputs ={\"question\":\"2024 icc t20 world cup winner?\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebcad1-ab52-4ed9-a065-485cac2a4362",
   "metadata": {
    "id": "c3ebcad1-ab52-4ed9-a065-485cac2a4362",
    "language": "python"
   },
   "source": [
    "## Kick off the agent pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd4ac6-a176-425f-8bf9-a15ef0075381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:12:16.098251Z",
     "iopub.status.busy": "2024-08-06T09:12:16.097908Z",
     "iopub.status.idle": "2024-08-06T09:12:22.448360Z",
     "shell.execute_reply": "2024-08-06T09:12:22.447696Z",
     "shell.execute_reply.started": "2024-08-06T09:12:16.098211Z"
    },
    "id": "4fcd4ac6-a176-425f-8bf9-a15ef0075381",
    "language": "python",
    "outputId": "9d5e82fc-87cc-4a8c-92d8-11d5845f9477",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result = rag_crew.kickoff(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9e58d-3c00-4cea-83d9-806a016f740b",
   "metadata": {
    "id": "caf9e58d-3c00-4cea-83d9-806a016f740b",
    "language": "python"
   },
   "source": [
    "## Obtain the final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e437fa-c3b3-4d1e-983b-93713a2df989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:12:44.362032Z",
     "iopub.status.busy": "2024-08-06T09:12:44.361665Z",
     "iopub.status.idle": "2024-08-06T09:12:44.366198Z",
     "shell.execute_reply": "2024-08-06T09:12:44.365344Z",
     "shell.execute_reply.started": "2024-08-06T09:12:44.362005Z"
    },
    "id": "49e437fa-c3b3-4d1e-983b-93713a2df989",
    "language": "python",
    "outputId": "92876ba8-429e-4d25-878b-744f372de4a2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c10aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupyterlab": {
   "notebooks": {
    "version_major": 6,
    "version_minor": 4
   }
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "singlestore_cell_default_language": "python",
  "singlestore_connection": {
   "connectionID": "a22b6f8b-b11b-4979-98da-98513e9876e6",
   "defaultDatabase": ""
  },
  "singlestore_row_limit": 300
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
